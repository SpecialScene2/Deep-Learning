{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the CIFAR-10\n",
    "def load_CIFAR10(pos, n_chunks=1):\n",
    "    Xtr = []\n",
    "    Ytr = []\n",
    "    for i in range(n_chunks):\n",
    "        train = unpickle(pos + '/data_batch_{0}'.format(i + 1))\n",
    "        Xtr.extend(train[b'data'])\n",
    "        Ytr.extend(train[b'labels'])\n",
    "        test = unpickle(pos + '/test_batch')\n",
    "        Xte = test[b'data']\n",
    "        Yte = test[b'labels']\n",
    "    return np.array(Xtr), np.array(Ytr), np.array(Xte), np.array(Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expresses the label data in one-hot encoding.\n",
    "def onehot_encoding (Ytr, Yte):\n",
    "    Ytr_onehot = np.zeros((Ytr.size, 10))\n",
    "    Yte_onehot = np.zeros((Yte.size, 10))\n",
    "    for i in range(Ytr.size):\n",
    "        Ytr_onehot[i][Ytr[i]] = 1\n",
    "    for i in range(Yte.size):\n",
    "        Yte_onehot[i][Yte[i]] = 1\n",
    "    return Ytr_onehot, Yte_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "Xtr, Ytr, Xte, Yte = load_CIFAR10('cifar-10-batches-py', 5)\n",
    "                                 \n",
    "# image data, each data size is 32*32*3\n",
    "Xtr = Xtr.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "Xte= Xte.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "\n",
    "# label data of train and test data, label data is represented by one-hot encoding\n",
    "Ytr_onehot, Yte_onehot = onehot_encoding(Ytr, Yte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "dropout_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Implement the layers of CNNs ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([3,3,3,32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "batch_mean, batch_var = tf.nn.moments(L1,[0])\n",
    "scale = tf.Variable(tf.ones([32,32,32]))\n",
    "beta = tf.Variable(tf.zeros([32,32,32]))\n",
    "L1 = tf.nn.batch_normalization(L1, batch_mean, batch_var,beta, scale, 1e-3)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides = [1,2,2,1], padding = \"SAME\")\n",
    "L1 = tf.nn.dropout(L1, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides = [1,1,1,1], padding = \"SAME\")\n",
    "\n",
    "batch_mean, batch_var = tf.nn.moments(L2,[0])\n",
    "scale = tf.Variable(tf.ones([16,16,64]))\n",
    "beta = tf.Variable(tf.zeros([16,16,64]))\n",
    "L2 = tf.nn.batch_normalization(L2, batch_mean, batch_var,beta, scale, 1e-3)\n",
    "\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize = [1,2,2,1], strides = [1,2,2,1], padding=\"SAME\")\n",
    "# L2 = tf.nn.dropout(L2, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W3= tf.Variable(tf.random_normal([3,3,64,128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides = [1,1,1,1], padding = \"SAME\")\n",
    "\n",
    "batch_mean, batch_var = tf.nn.moments(L3,[0])\n",
    "scale = tf.Variable(tf.ones([8,8,128]))\n",
    "beta = tf.Variable(tf.zeros([8,8,128]))\n",
    "L3 = tf.nn.batch_normalization(L3, batch_mean, batch_var,beta, scale, 1e-3)\n",
    "\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W4= tf.Variable(tf.random_normal([3,3,128,256], stddev=0.01))\n",
    "L4 = tf.nn.conv2d(L3, W4, strides = [1,1,1,1], padding = \"SAME\")\n",
    "\n",
    "batch_mean, batch_var = tf.nn.moments(L4,[0])\n",
    "scale = tf.Variable(tf.ones([8,8,256]))\n",
    "beta = tf.Variable(tf.zeros([8,8,256]))\n",
    "L4 = tf.nn.batch_normalization(L4, batch_mean, batch_var,beta, scale, 1e-3)\n",
    "\n",
    "L4 = tf.nn.relu(L4)\n",
    "# L4 = tf.nn.dropout(L4, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W5= tf.Variable(tf.random_normal([3,3,256,512], stddev=0.01))\n",
    "L5 = tf.nn.conv2d(L4, W5, strides = [1,1,1,1], padding = \"SAME\")\n",
    "\n",
    "batch_mean, batch_var = tf.nn.moments(L5,[0])\n",
    "scale = tf.Variable(tf.ones([8,8,512]))\n",
    "beta = tf.Variable(tf.zeros([8,8,512]))\n",
    "L5 = tf.nn.batch_normalization(L5, batch_mean, batch_var,beta, scale, 1e-3)\n",
    "\n",
    "L5 = tf.nn.relu(L5)\n",
    "L5 = tf.nn.dropout(L5, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#512\n",
    "W6 = tf.Variable(tf.random_normal([8*8*512, 512], stddev = 0.01))\n",
    "L6 = tf.reshape(L5, [-1, 8*8*512])\n",
    "L6 = tf.matmul(L6, W6)\n",
    "\n",
    "batch_mean, batch_var = tf.nn.moments(L6,[0])\n",
    "scale = tf.Variable(tf.ones([512]))\n",
    "beta = tf.Variable(tf.zeros([512]))\n",
    "L6 = tf.nn.batch_normalization(L6, batch_mean, batch_var,beta, scale, 1e-3)\n",
    "\n",
    "L6 = tf.nn.relu(L6)\n",
    "#dropout\n",
    "L6 = tf.nn.dropout(L6, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W7 = tf.Variable(tf.random_normal([512,10],stddev = 0.01))\n",
    "model = tf.matmul(L6, W7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost and optimizer\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.002\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.002).minimize(cost)\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(cost)\n",
    "# optimizer = tf.train.AdadeltaOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Implement the train process ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "total_batch = int(len(Xtr) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg.cost =  1.312\n",
      "Accuracy 0.656\n",
      "Epoch: 0002 Avg.cost =  0.953\n",
      "Accuracy 0.7186\n",
      "Epoch: 0003 Avg.cost =  0.807\n",
      "Accuracy 0.7557\n",
      "Epoch: 0004 Avg.cost =  0.707\n",
      "Accuracy 0.7748\n",
      "Epoch: 0005 Avg.cost =  0.642\n",
      "Accuracy 0.7851\n",
      "Epoch: 0006 Avg.cost =  0.591\n",
      "Accuracy 0.7903\n",
      "Epoch: 0007 Avg.cost =  0.549\n",
      "Accuracy 0.7919\n",
      "Epoch: 0008 Avg.cost =  0.508\n",
      "Accuracy 0.798\n",
      "Epoch: 0009 Avg.cost =  0.468\n",
      "Accuracy 0.8043\n",
      "Epoch: 0010 Avg.cost =  0.437\n",
      "Accuracy 0.8065\n",
      "Epoch: 0011 Avg.cost =  0.403\n",
      "Accuracy 0.8121\n",
      "Epoch: 0012 Avg.cost =  0.378\n",
      "Accuracy 0.8153\n",
      "Epoch: 0013 Avg.cost =  0.360\n",
      "Accuracy 0.8252\n",
      "Epoch: 0014 Avg.cost =  0.329\n",
      "Accuracy 0.8119\n",
      "Epoch: 0015 Avg.cost =  0.315\n",
      "Accuracy 0.8137\n",
      "Epoch: 0016 Avg.cost =  0.294\n",
      "Accuracy 0.8172\n",
      "Epoch: 0017 Avg.cost =  0.268\n",
      "Accuracy 0.8232\n",
      "Epoch: 0018 Avg.cost =  0.256\n",
      "Accuracy 0.823\n",
      "Epoch: 0019 Avg.cost =  0.241\n",
      "Accuracy 0.8192\n",
      "Epoch: 0020 Avg.cost =  0.233\n",
      "Accuracy 0.819\n",
      "Epoch: 0021 Avg.cost =  0.220\n",
      "Accuracy 0.8168\n",
      "Epoch: 0022 Avg.cost =  0.209\n",
      "Accuracy 0.8263\n",
      "Epoch: 0023 Avg.cost =  0.203\n",
      "Accuracy 0.8219\n",
      "Epoch: 0024 Avg.cost =  0.188\n",
      "Accuracy 0.8234\n",
      "Epoch: 0025 Avg.cost =  0.176\n",
      "Accuracy 0.8218\n",
      "Epoch: 0026 Avg.cost =  0.162\n",
      "Accuracy 0.8265\n",
      "Epoch: 0027 Avg.cost =  0.160\n",
      "Accuracy 0.8256\n",
      "Epoch: 0028 Avg.cost =  0.153\n",
      "Accuracy 0.8271\n",
      "Epoch: 0029 Avg.cost =  0.143\n",
      "Accuracy 0.8248\n",
      "Epoch: 0030 Avg.cost =  0.136\n",
      "Accuracy 0.8192\n",
      "Epoch: 0031 Avg.cost =  0.130\n",
      "Accuracy 0.8207\n",
      "Epoch: 0032 Avg.cost =  0.132\n",
      "Accuracy 0.8203\n",
      "Epoch: 0033 Avg.cost =  0.127\n",
      "Accuracy 0.8239\n",
      "Epoch: 0034 Avg.cost =  0.126\n",
      "Accuracy 0.8242\n",
      "Epoch: 0035 Avg.cost =  0.118\n",
      "Accuracy 0.8273\n",
      "Epoch: 0036 Avg.cost =  0.113\n",
      "Accuracy 0.8311\n",
      "Epoch: 0037 Avg.cost =  0.113\n",
      "Accuracy 0.8325\n",
      "Epoch: 0038 Avg.cost =  0.106\n",
      "Accuracy 0.8299\n",
      "Epoch: 0039 Avg.cost =  0.101\n",
      "Accuracy 0.829\n",
      "Epoch: 0040 Avg.cost =  0.103\n",
      "Accuracy 0.8312\n",
      "Epoch: 0041 Avg.cost =  0.099\n",
      "Accuracy 0.832\n",
      "Epoch: 0042 Avg.cost =  0.097\n",
      "Accuracy 0.8282\n",
      "Epoch: 0043 Avg.cost =  0.090\n",
      "Accuracy 0.8348\n",
      "Epoch: 0044 Avg.cost =  0.087\n",
      "Accuracy 0.833\n",
      "Epoch: 0045 Avg.cost =  0.081\n",
      "Accuracy 0.8343\n",
      "Epoch: 0046 Avg.cost =  0.081\n",
      "Accuracy 0.8334\n",
      "Epoch: 0047 Avg.cost =  0.079\n",
      "Accuracy 0.8346\n",
      "Epoch: 0048 Avg.cost =  0.075\n",
      "Accuracy 0.8342\n",
      "Epoch: 0049 Avg.cost =  0.079\n",
      "Accuracy 0.8284\n",
      "Epoch: 0050 Avg.cost =  0.073\n",
      "Accuracy 0.8345\n"
     ]
    }
   ],
   "source": [
    "#dropout_prob:0.6\n",
    "#range : 35\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_cost=0\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = Xtr[i*batch_size:(i+1)*batch_size], Ytr_onehot[i*batch_size:(i+1)*batch_size]\n",
    "        #batch_xs = batch_xs.reshape(-1, 32, 32, 3)\n",
    "        _, curr_loss = sess.run([optimizer, cost],feed_dict={X:batch_xs, \n",
    "                                                             Y:batch_ys,\n",
    "                                                            dropout_prob: 0.6})\n",
    "        total_cost += curr_loss\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\" % (epoch +1),\"Avg.cost = \", \"{:,.3f}\".format(total_cost/total_batch))\n",
    "    correctness = tf.equal(tf.argmax(model,1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "    print('Accuracy', sess.run(accuracy, feed_dict = {X:Xte,\n",
    "                                                      Y:Yte_onehot,\n",
    "                                                      dropout_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Implement the test process ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8345\n"
     ]
    }
   ],
   "source": [
    "correctness = tf.equal(tf.argmax(model,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "print('Accuracy', sess.run(accuracy, feed_dict = {X:Xte,\n",
    "                                                  Y:Yte_onehot,\n",
    "                                                  dropout_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
