{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-c6b366435aa2>\", line 5, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 69, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"C:\\Users\\Genius Scene\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "train.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c6b366435aa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;31m# You don't need to modify this part.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-c6b366435aa2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;31m# You don't need to modify this function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m     \u001b[0mwrite_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-c6b366435aa2>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows)\u001b[0m\n\u001b[0;32m   1510\u001b[0m                 \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rbU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m                 \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1513\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_file_openers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: train.csv not found."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "if \"DISPLAY\" not in os.environ:\n",
    "    # remove Travis CI Error\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "def predict(file):\n",
    "    def normalization_2d(data):\n",
    "        for i in range(len(data)):\n",
    "            for j in range(6):\n",
    "                data[i][j] = (data[i][j]-raw_mean)/raw_std\n",
    "        return data\n",
    "\n",
    "    def normalization(data):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = (data[i]-raw_mean)/raw_std\n",
    "        return data\n",
    "\n",
    "    def denormalization(data):\n",
    "        for i in range(len(data)):\n",
    "             data[i] = (data[i] * raw_std)+raw_mean\n",
    "        return data\n",
    "\n",
    "    def denormalization_2d(data):\n",
    "        for i in range(len(data)):\n",
    "            for j in range(6):\n",
    "                data[i][j] = (data[i][j] * raw_std)+raw_mean\n",
    "        return data\n",
    "\n",
    "    train = genfromtxt('train.csv', delimiter=',', skip_header=1, usecols=(1, 2, 3, 4, 5, 6))\n",
    "    label = genfromtxt('train.csv', delimiter=',', skip_header=1, usecols=(7))\n",
    "    raw = genfromtxt('train.csv', delimiter=',', skip_header=1, usecols=(1))\n",
    "\n",
    "    # 예측해야할 test\n",
    "    test = genfromtxt('train.csv', delimiter=',', skip_header=1, usecols=(1,2,3,4,5,6))\n",
    "    # 예측한 결과를 담아야 할 result (test에서 구한거 denormalization 해야 함.)\n",
    "\n",
    "    raw_mean = np.mean(raw)\n",
    "    raw_std = np.std(raw)\n",
    "    print(np.mean(raw), np.std(raw))\n",
    "\n",
    "    # normalization\n",
    "    normalization_2d(train)\n",
    "    normalization(label)\n",
    "    normalization(test)\n",
    "\n",
    "    # Data Split (train : 70%, test : 30 %) /\n",
    "    # IDEA : Hyper-parameter 정할 땐 valid set 활용 하고 최종 학습 할 땐 train 100 다 사용 하기.\n",
    "    train_size = int(len(train) * 0.9)\n",
    "    print(\"Train_Size :\", train_size)\n",
    "    test_size = len(train) - train_size\n",
    "    trainX, validX = np.array(train[0:train_size]), np.array(train[train_size:len(train)])\n",
    "    trainY, validY = np.array(label[0:train_size]), np.array(label[train_size:len(train)])\n",
    "\n",
    "    # train Parameters\n",
    "    seq_length = 6  # 6일이라서 seq_length는 6이다.\n",
    "    data_dim = 1  # 6일의 통으로 되어있는 data가 온도라는 피쳐 1개로 이루어져있음을 뜻함.\n",
    "    # 이전 hidden_dim : 10 40 160 640 1000\n",
    "    hidden_dim = 512\n",
    "    output_dim = 1\n",
    "    learning_rate = 0.001\n",
    "    # 이전 iterations = 200 400 800 1600\n",
    "    iterations = 60\n",
    "\n",
    "    trainX_Li = []\n",
    "    trainY_Li = []\n",
    "    for i in range(0, len(trainY) - seq_length):\n",
    "        _x = trainX[i]\n",
    "        _y = trainY[i + seq_length]\n",
    "        #     print(_x, \"->\", _y)\n",
    "        trainX_Li.append(_x)\n",
    "        trainY_Li.append(_y)\n",
    "\n",
    "    trainX_Li = np.array(trainX_Li)\n",
    "    trainX_Li = trainX_Li.reshape(-1, 6, 1)\n",
    "\n",
    "    trainY_Li = np.array(trainY_Li)\n",
    "    trainY_Li = trainY_Li.reshape(-1, 1)\n",
    "\n",
    "    # 2) Valid Dataset\n",
    "    # build a Valid Dataset for correct shpae\n",
    "    validX_Li = []\n",
    "    validY_Li = []\n",
    "    for i in range(0, len(validY) - seq_length):\n",
    "        _x = validX[i]\n",
    "        _y = validY[i + seq_length]  # Next close price\n",
    "        #     print(_x, \"->\", _y)\n",
    "        validX_Li.append(_x)\n",
    "        validY_Li.append(_y)\n",
    "\n",
    "    validX_Li = np.array(validX_Li)\n",
    "    validX_Li = validX_Li.reshape(-1, 6, 1)\n",
    "\n",
    "    validY_Li = np.array(validY_Li)\n",
    "    validY_Li = validY_Li.reshape(-1, 1)\n",
    "\n",
    "    # 3) Valid Dataset\n",
    "    # build a Valid Dataset for correct shpae\n",
    "    test_Li = []\n",
    "    for i in range(0, len(test) - seq_length):\n",
    "        _x = test[i]\n",
    "        #     print(_x, \"->\", _y)\n",
    "        test_Li.append(_x)\n",
    "\n",
    "    test_Li = np.array(test_Li)\n",
    "    test_Li = test.reshape(-1, 6, 1)\n",
    "\n",
    "    print(trainX_Li.shape)\n",
    "    print(trainY_Li.shape)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    cells = []\n",
    "    dropout = tf.placeholder(tf.float32)\n",
    "    #이전 range(5)\n",
    "    # for _ in range(3):\n",
    "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim)\n",
    "    #     rnn_cell = tf.contrib.rnn.DropoutWrapper(rnn_cell, output_keep_prob=1.0 - 0.3)\n",
    "    # cells.append(rnn_cell)\n",
    "    # rnn_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "    outputs, _states = tf.nn.dynamic_rnn(rnn_cell, X, dtype=tf.float32)\n",
    "    Y_pred = tf.contrib.layers.fully_connected(\n",
    "        outputs[:, -1], output_dim, activation_fn=None, normalizer_fn = tf.contrib.slim.batch_norm)  # We use the last cell's output\n",
    "\n",
    "    # cost/loss\n",
    "    loss = tf.reduce_sum(tf.square(Y_pred - Y))  # mean of the squares\n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    # RMSE\n",
    "    targets = tf.placeholder(tf.float32, [None, 1])\n",
    "    predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "    # print(validX_Li)\n",
    "    losses = []\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        # Training step\n",
    "        for i in range(iterations):\n",
    "            _, step_loss = sess.run([train, loss], feed_dict={\n",
    "                                    X: trainX_Li, Y: trainY_Li})\n",
    "            print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "            losses.append(step_loss)\n",
    "        # Test step\n",
    "        train_predict = sess.run(Y_pred, feed_dict={X: trainX_Li})\n",
    "        test_predict = sess.run(Y_pred, feed_dict={X: validX_Li})\n",
    "        # inverse normalize\n",
    "        train_predict = denormalization(train_predict)\n",
    "        test_predict = denormalization(test_predict)\n",
    "        trainY_Li = denormalization(trainY_Li)\n",
    "        print('valid',validY_Li)\n",
    "        #RMSE\n",
    "        rmse_val_tr = sess.run(rmse, feed_dict={\n",
    "                        targets: trainY_Li, predictions: train_predict})\n",
    "        print(\"TRAIN_RMSE: {}\".format(rmse_val_tr))\n",
    "        rmse_val = sess.run(rmse, feed_dict={\n",
    "                        targets: validY_Li, predictions: test_predict})\n",
    "        print(\"TEST_RMSE: {}\".format(rmse_val))\n",
    "    #     과제 제출용 step\n",
    "        test_predict = sess.run(Y_pred, feed_dict={X:test_Li})\n",
    "\n",
    "        print('complete')\n",
    "\n",
    "        finalResult = []\n",
    "        for i in test_predict:\n",
    "            finalResult.append(i[0])\n",
    "        denormalization(finalResult)\n",
    "        return finalResult\n",
    "\n",
    "def write_result(predictions):\n",
    "    # You don't need to modify this function.\n",
    "    with open('result.csv', 'w') as f:\n",
    "        f.write('Value\\n')\n",
    "        for l in predictions:\n",
    "            f.write('{}\\n'.format(l))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # You don't need to modify this function.\n",
    "    predictions = predict('test.csv')\n",
    "    write_result(predictions)\n",
    "if __name__ == '__main__':\n",
    "    # You don't need to modify this part.\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
